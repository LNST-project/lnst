This TODO document contains features and larger items that still need or we want
them to be implemented in Python Recipes, with notes where relevant.

* finalisation of the Device API
    * reimplementation of properties and Device creation
    * Device::destroy log warning and don't do cleanup?
    * Device::destroy rename to delete or rename DeviceDeleted exception to
      Destroyed?

* wait/sleep method that cycles handles ctl <-> agent communication in the
  background
    * should include wait for condition functionality, e.g. wait for Device
      LOWER_UP. jpirko also wants to be able to associate this with timestamps,
      e.g. - wait for LOWER_UP that's been in effect for at least 5 seconds. So
      if the device isn't LOWER_UP it will wait for that to happen and then
      wait for 5 seconds, or if the device has been LOWER_UP for e.g. 3
      seconds, we will wait for additional 2 seconds, however if it has been up
      for e.g. 8 seconds the wait will return immediatelly.
    * currently supporting waiting on condition (a method) on the controller,
      possible next work is to expand this to the agent as well (problems with
      object references)

* netlink descriptive error logging - ask jbenc

* Current machine configuration dump describing the "full"(relevant?)
  configuration of a host. We need this for PerfRepo integration to generate
  hashes, but it should also be useful just in general...

* support for custom device classes (not necessarily located in the
  lnst.Devices package)
  * must inherit from base Device class
  * currently only files/classes in lnst.Devices package are synchronized as
    Device classes, but we have the capability to sync arbitrary python code so
    this shouldn't be too big a problem


* Port test_modules
    * Netperf needs to be resynced with the legacy version there are some
      features and bugfixes missing from the currently ported version

* Ip address/network generators

* breakpoints in tests
    * we want the ability to stop in the middle of the test so we can manually
      enter the test systems
    * interactive LNST mode could also be interesting
    * we could use native python debugging facilities
    * or implement our own solution if required to satisfy unique requirements
      of LNST -- long running connections to agents and handling messages
      during the breakpoint

* agent machine descriptions in a different format than XML
    * separate parsing agent descriptions into it's own class so that this can
      be drop-in replaced with anything

* minimize the agent application (Host API abstraction)- it should only provide
  the bare minimum functionality, all other functionality should be dynamically
  sent from the Controller (same as Device classes)

* test tools - concept from old XML LNST, we should think of some kind of an
  equivalent. I think the new sync mechanism could be exported as an API to the
  tester and that could help with that

* malformed cache -> delete and create new








============== DONE ==============
* rootns rename to initns

* Netnamespace.name instead of nsname

* RemoteDevice.host to _host -> Machine object shouldn't be accessible
    .host should be the initns on the machine
    str(Host/Namespace) == str(Host/Namespace.name)

* disable all Devices by default and enable only those that are in the machine
  xml, also think about having an API for manual control
    - statistics during deconfiguration also for just these devices
        - bulk agent method, remove autodump at deconfiguration, make this
          manual

* Params should be just self.params.x, also x in self.params should tell us if
  it was set or not --> implement def __contains__(self, item)

* netlink sockets leaking

* go through master to check for bugs that can be backported

* fix git version check - if git not installed raise Exception/report error
    version checks are now implemented differently

* Results implementation
    * Result objects should be stored in a transparent way and there should be
      a way to access and export them in different ways, default being the
      Result summary at the end of stdout logs.
    * Summary format proposal (copied from the api description document):
        Since I've changed how Job execution is handled, I've also wrote down a
        proposal to change how we log Recipe results - the RESULTS SUMMARY logs at the
        end of a recipe run. I haven't started working on it yet, I've just wrote an
        example on paper which I'm copying here. Any comments are appreciated.

        RESULTS SUMMARY:
        Host m1 Job 1    XYZ       PASS/FAIL
                          Formatted results:
                            ...
        Host m2 Job 1    XYZ        started
        Host m1 Job 3    XYZ        PASS/FAIL
                          Formatted results:
                            ...
        Host m2 Job 1    XYZ        PASS/FAIL
                          Formatted results:
                            ...
        Custom summary record....   (optional PASS/FAIL)
                            ... optional additional data
                            ... i still need to figure out how this will look like

        The main difference to the old results summary is that Jobs have numerical ids
        that are unique per host, and you ALWAYS see the id (previously only background
        commands had ids). Since all Jobs "run in background" this will make matching
        "started" "finished" logs easier. There also won't be any more "kill cmd" "intr
        cmd" logs here since these commands don't exist anymore.

        Since "all Jobs are in background" it means that in reality all of them
        generate a "started" and "finished" log, however, if these are in a direct
        sequence after each other they get shortened to just the PASS/FAIL log. This
        will also be true for background commands if there were no results to report
        between their start and finish.

* API for "first" ip in list limited by selector
    added ips_filter method to Device class
