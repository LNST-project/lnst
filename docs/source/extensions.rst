.. _containerized:

LNST in containers
==================
LNST supports running both agents and controller in containers at the host machine.
LNST uses custom RPC protocol to communicate between controller and agents which 
uses separate network interface to not interfere with test and so, it doesn't matter
where controller and agents are running as long as they can communicate.

With support of running LNST in containers your machine setup might look like this:

1. both controller and agents are running on your baremetal machines

2. controller is running on your baremetal machine and agents are running in containers

3. controller is running in container and agents are running on your baremetal machine

4. both controller and agents are running in containers


This article describes how to run individual parts of LNST in containers. If you want
to run either controller or agents on baremetal see :ref:`installation` section.


Common requirements
-------------------
We recommend to use Podman as this was developed and tested with Podman but should
work with Docker as well.

If you want to use Podman, follow installation steps on
`official Podman installation page <https://podman.io/getting-started/installation>`_.


.. _containerized_agents:

Containerized agents
--------------------

Containers and networks are dynamically created based on recipe requirements.
Containers are also automatically connected to networks.

Requirements
````````````
The first requirement is **Podman**, follow installation steps on
`official Podman installation page <https://podman.io/getting-started/installation>`_.


Configure Podman to use CNI
+++++++++++++++++++++++++++

If you use Podman 4.0+ you need to change default network backend from `netavark` to `CNI` as LNST supports CNI
only. If your Podman is already running, stop it.


1. Remove all the LNST's leftovers from `/etc/cni/net.d/lnst_*.conflist` if you already tried to run LNST

2. Set default network backend to `cni`, add following block to `containers.conf` -
`documentation <https://github.com/containers/common/blob/main/docs/containers.conf.5.md>`_:

  .. code-block:: toml

    [network]
    network_backend="cni"

3. Install `CNI` plugins:

  .. code-block:: bash

    dnf install containernetworking-plugins

4. Start your Podman instance


Podman API is also required, follow the steps below:

Enabling Podman API service:
++++++++++++++++++++++++++++

.. code-block:: bash

    systemctl enable --now podman.socket

and get socket URL:

.. code-block:: bash

    systemctl status podman.socket | grep "Listen:"

Starting Podman API manually:
+++++++++++++++++++++++++++++
If you don't want to run Podman API as a service, you can start it manually.
Don't forget to run the command below with root privileges.

.. code-block:: bash

    podman system service --timeout 0 --log-level=debug

Socket URL could be found at the top of logs generated by this command.

The usual URL is `unix:/run/podman/podman.sock`

Build LNST agent image
``````````````````````
Currently, LNST does not support automated building, so build LNST agent
machine image.

Podman uses different `storage <https://docs.podman.io/en/latest/markdown/podman.1.html#root-value>`_ locations
for root-full and root-less images, so make sure
you build image to root-full storage.
LNST currently uses the default storage location.
Build context should be a directory, where your LNST project is located.

*Your local copy of LNST is used by agents in containers.*

Use -t argument to name your image, this name is later used.

.. code-block:: bash

    cd your_lnst_project_directory
    podman build . -t lnst -f container_files/agent/Dockerfile


Now is everything ready to run LNST in containers.
For testing purposes, we can use `HelloWorldRecipe` from :ref:`hello-world-script`.

Only initialization of `Controller()` object has to be changed:

.. code-block:: python

    from lnst.Controller.MachineMapper import ContainerMapper
    from lnst.Controller.ContainerPoolManager import ContainerPoolManager

    podman_uri = ""  # podman URI from installation step above
    image_name = ""  # name of image from build step above
    ctl = Controller(poolMgr=ContainerPoolManager, mapper=ContainerMapper, podman_uri=podman_uri, image=image_name)


And run the script.

Classes documentation
`````````````````````
.. autoclass:: lnst.Controller.MachineMapper.ContainerMapper
    :members:


.. automodule:: lnst.Controller.ContainerPoolManager
    :members: ContainerPoolManager


Containerized controller
------------------------

Using containerized agents
``````````````````````````

Before proceeding with containerized controller, you need to build LNST
agent image (see :ref:`containerized_agents`) you also need to provide
following parameters as environment variables to controller container:

* `PODMAN_URI` - URI to Podman socket, e.g. `tcp://localhost[:port]`. This needs to be accessible from container.
* `IMAGE_NAME` - name of the image you built for agents.

It expects that you use CNI as network backend for Podman.


Using baremetal agents
``````````````````````
Firstly, you need to prepare machine XMLs if you decide to run agents on baremetal
machines (see :ref:`machines-pool`). Instead of putting them into `~/.lnst/pool`
directory, you need to put them into `container_files/controller/pool` directory.
Machine XMLs are copied to container during build process from
`container_files/controller/pool`.
Podman doesn't support copying files located outside of build context, so you
need to put it to LNST project directory.

.. note::
   To avoid having to deal with pool files you can simply mount your `~/.lnst/pool` directory
   to `/root/.lnst/pool/` in the container (read-only access is sufficient). 


Build and run controller
````````````````````````

Build the controller image:

.. code-block:: bash

    cd your_lnst_project_directory
    podman build . -t lnst_controller -f container_files/controller/Dockerfile

This will copy pool files to `/root/.lnst/pool/` in container and LNST from
`your_lnst_project_directory` to `/lnst` in container.

.. note::
   If you want to avoid rebuilding the image every time you change your LNST project (e.g. during
   development), you can mount `your_lnst_project_directory` to `/lnst` in container. The LNST's
   virtual environment is located outside of `/lnst/` directory, so if your changes requires
   reinstallation fo LNST and/or its dependencies, you need to rebuild the image.


Before running the container, you need to provide environment variables:

* `RECIPE` - name of recipe class, these are loaded from `lnst.Recipes.ENRT` as wildcard import
* `RECIPE_PARAMS` - `;` separated list of parameters for recipe. Each parameter is in format `key=value`
* `FORMATTERS` - `;` separated list of formatters, these are loaded from `lnst.Formatters` as wildcard import
* `DEBUG` - enables/disables LNST's debug mode

.. warning::
   `RECIPE`, `RECIPE_PARAMS` and `FORMATTERS` are parsed using Python's `eval` function,
   which is a security risk. Make sure you trust the source of these variables.

Now, you can run the controller:

.. code-block:: bash

    podman run -e RECIPE=SimpleNetworkRecipe -e RECIPE_PARAMS="perf_iterations=1;perf_duration=10" -e DEBUG=1 --rm --name lnst_controller lnst_controller


.. note::
   Podman containers are by default NATed, so you may need to use some other `--network` mode
   to make agent machines reachable from controller container. If agent machines are reachable
   from your host machine, `--network=host` should do the job. Read
   `Podman's documentation <https://github.com/containers/podman/blob/main/docs/tutorials/basic_networking.md#basic-network-setups>`_
   first.


Or you can run more complex recipes:

.. code-block:: bash

    podman run -e RECIPE=XDPDropRecipe -e RECIPE_PARAMS="perf_iterations=1;perf_tool_cpu=[0,1];multi_dev_interrupt_config={'host1':{'eth0':{'cpus':[0],'policy':'round-robin'}}}" --rm --name lnst_controller lnst_controller


Classes documentation
`````````````````````
.. autoclass:: container_files.controller.container_runner.ContainerRunner
    :members:

